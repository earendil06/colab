{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab-deep-daze",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMOyHqy8wt1H"
      },
      "source": [
        "# Colab-deep-daze\n",
        "Original repo: [lucidrains/deep-daze](https://github.com/lucidrains/deep-daze)\n",
        "\n",
        "My fork: [styler00dollar/Colab-deep-daze](https://github.com/styler00dollar/Colab-deep-daze)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP3u8c3IpMld"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55YJsbFV10i8"
      },
      "source": [
        "#@title Install\n",
        "import subprocess\n",
        "\n",
        "CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
        "print(\"CUDA version:\", CUDA_version)\n",
        "\n",
        "if CUDA_version == \"10.0\":\n",
        "    torch_version_suffix = \"+cu100\"\n",
        "elif CUDA_version == \"10.1\":\n",
        "    torch_version_suffix = \"+cu101\"\n",
        "elif CUDA_version == \"10.2\":\n",
        "    torch_version_suffix = \"\"\n",
        "else:\n",
        "    torch_version_suffix = \"+cu110\"\n",
        "\n",
        "! pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex\n",
        "!pip install deep-daze"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cskITQNpwEW6"
      },
      "source": [
        "# Using Google Drive and disabling heavy printing to avoid output size limit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCBTrL3XqXf-",
        "cellView": "form"
      },
      "source": [
        "#@title Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print('Google Drive connected.')\n",
        "!mkdir '/content/drive/MyDrive/DeepDaze/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy2SvlEMxHVH"
      },
      "source": [
        "Current default is ```!mkdir '/content/drive/MyDrive/DeepDaze/'```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IPQ_rdA2Sa7"
      },
      "source": [
        "from tqdm import tqdm\n",
        "from IPython.display import Image, display\n",
        "import shutil, os\n",
        "\n",
        "from deep_daze import Imagine\n",
        "\n",
        "save_path = '/content/drive/MyDrive/DeepDaze/' #@param {type:\"string\"}\n",
        "TEXT = 'sad anime character' #@param {type:\"string\"}\n",
        "TEXT_PATH = TEXT.replace(\" \", \"_\")\n",
        "NUM_LAYERS = 32 #@param {type:\"number\"}\n",
        "\n",
        "model = Imagine(\n",
        "    text = TEXT,\n",
        "    num_layers = NUM_LAYERS,\n",
        "    save_every = 50 #@param {type:\"number\"}\n",
        ")\n",
        "\n",
        "# without heavy printing and saving images to drive\n",
        "for epoch in range(20):\n",
        "    for i in range(1000):\n",
        "        model.train_step(epoch, i)\n",
        "\n",
        "        if i % model.save_every != 0:\n",
        "            continue\n",
        "\n",
        "        file_end = str(\"_\"+str({epoch})+\"_\"+str({i})+\".jpg\")\n",
        "        source = f'{TEXT_PATH}.jpg'\n",
        "        destination = f'{save_path}{TEXT_PATH}{file_end}'\n",
        "        print(source, destination)\n",
        "        shutil.copy(source, destination)\n",
        "        os.remove(source)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}